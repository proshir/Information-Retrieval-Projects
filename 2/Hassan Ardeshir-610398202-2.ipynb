{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87e9e5e2-b408-4136-8def-29118b0ee242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in d:\\projects\\ri\\env\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: Levenshtein==0.23.0 in d:\\projects\\ri\\env\\lib\\site-packages (from python-Levenshtein) (0.23.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in d:\\projects\\ri\\env\\lib\\site-packages (from Levenshtein==0.23.0->python-Levenshtein) (3.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1cf502-c3c7-46ba-8982-b7ff8a3dea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from Levenshtein import distance\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa86be70-03b1-4acd-ac83-70d3b3eba84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Proshir-\n",
      "[nltk_data]     Pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Proshir-\n",
      "[nltk_data]     Pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0076f70e-7c93-4888-9fa2-f4e8f68eeb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UndefinedQueryInputError(Exception):\n",
    "    def __init__(self):\n",
    "        self.message = \"Undefined query input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8323ed12-38b5-48c0-ad1a-087c1ee3d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRSystem:\n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "        self.inverted_index = {}\n",
    "        self.positional_index = {}\n",
    "        self.all_cterms = set()\n",
    "        self.all_kterms = {}\n",
    "        self.kgram_index = {}\n",
    "\n",
    "    def prep_correct_col(self):\n",
    "        folder_path = \"docs\"\n",
    "        self.all_cterms = set()\n",
    "        self.all_kterms = {}\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                document_text = file.read()\n",
    "                self.add_data_correct(document_text)\n",
    "        for w_id, word in enumerate(self.all_cterms):\n",
    "            self.all_kterms[w_id] = word\n",
    "    \n",
    "    def preprocess_document(self, words, rm_stop=False, do_stem=False):\n",
    "        # Remove Stop Words\n",
    "        if rm_stop:\n",
    "            stop_words = set(stopwords.words(\"english\"))\n",
    "            words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        # Stemming\n",
    "        if do_stem:\n",
    "            stemmer = PorterStemmer()\n",
    "            words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "        return words\n",
    "\n",
    "    def apreprocess_document(self, document):\n",
    "        # Tokenization\n",
    "        words = word_tokenize(document)\n",
    "    \n",
    "        # Lowercasing and Remove punctuation\n",
    "        words = [word.lower() for word in words if word.isalnum()]\n",
    "\n",
    "        return words\n",
    "\n",
    "    def bpreprocess_document(self, document, rm_stop=False, do_stem=False):\n",
    "        words = self.apreprocess_document(document)\n",
    "        return self.preprocess_document(words, rm_stop, do_stem)\n",
    "    \n",
    "    def add_document(self, document):\n",
    "        document = self.apreprocess_document(document)\n",
    "        self.documents += [document]\n",
    "\n",
    "    def add_data_correct(self, document):\n",
    "        words = self.apreprocess_document(document)\n",
    "        self.all_cterms |= set(words)\n",
    "                \n",
    "    def build_inverted_index(self, rm_stop=True, do_stem=True):\n",
    "        self.inverted_index = {}\n",
    "        for doc_id, document in enumerate(self.documents):\n",
    "            terms = self.preprocess_document(document, rm_stop, do_stem)\n",
    "            \n",
    "            for term in terms:\n",
    "                if term not in self.inverted_index:\n",
    "                    self.inverted_index[term] = [doc_id]\n",
    "                elif self.inverted_index[term][-1] != doc_id:\n",
    "                    self.inverted_index[term] += [doc_id]\n",
    "\n",
    "    def get_inv_index(self, term):\n",
    "        return self.inverted_index.get(term, [])\n",
    "    \n",
    "    def intersect_sorted(self, so1, so2):\n",
    "        i, j = 0, 0\n",
    "        if len(so1) > len(so2): # change order of intersect based on their size (freq)\n",
    "            so1, so2 = so2, so1\n",
    "        result = []\n",
    "        while i < len(so1) and j < len(so2):\n",
    "            doc1 = so1[i]\n",
    "            while j < len(so2) and so2[j] < doc1:\n",
    "                j += 1\n",
    "            if j == len(so2):\n",
    "                break\n",
    "            if doc1 == so2[j]:\n",
    "                result += [doc1]\n",
    "            i += 1        \n",
    "        return result\n",
    "\n",
    "    def merge_sorted(self, so1, so2):\n",
    "        i, j = 0, 0\n",
    "        result = []\n",
    "        while i < len(so1):\n",
    "            doc1 = so1[i]\n",
    "            while j < len(so2) and so2[j] <= doc1:\n",
    "                if doc1 != so2[j]:\n",
    "                    result += [so2[j]]\n",
    "                j += 1\n",
    "            result += [doc1]\n",
    "            i += 1\n",
    "        while j < len(so2):\n",
    "            result += so2[j]\n",
    "            j += 1\n",
    "        return result\n",
    "\n",
    "    def not_sorted(self, so):\n",
    "        j = 0\n",
    "        result = []\n",
    "        for i in range(len(self.documents)):\n",
    "            if j == len(so) or so[j] != i:\n",
    "                result += [i]\n",
    "            else:\n",
    "                j += 1\n",
    "        return result\n",
    "\n",
    "    def boolean_query(self, query, rm_stop=True, do_stem=True):\n",
    "        terms = re.findall(r'\\b\\w+\\b', query.lower())\n",
    "        order = None\n",
    "        if len(terms) == 3:\n",
    "            if terms[1] == \"and\":\n",
    "                order = \"and\"\n",
    "            elif terms[1] == \"or\":\n",
    "                order = \"or\"\n",
    "            terms = self.bpreprocess_document(f\"{terms[0]} {terms[2]}\", rm_stop, do_stem) \n",
    "        elif len(terms) == 2 and terms[0] == \"not\":\n",
    "            order = \"not\"\n",
    "            terms = self.bpreprocess_document(terms[1], rm_stop, do_stem) \n",
    "        if order == None:\n",
    "            raise UndefinedQueryInputError()\n",
    "\n",
    "        if order == \"and\":\n",
    "            return self.intersect_sorted(self.get_inv_index(terms[0]), self.get_inv_index(terms[1]))\n",
    "        elif order == \"or\":\n",
    "            return self.merge_sorted(self.get_inv_index(terms[0]), self.get_inv_index(terms[1]))\n",
    "        else:\n",
    "            return self.not_sorted(self.get_inv_index(terms[0]))\n",
    "\n",
    "    def build_positional_index(self, rm_stop=False, do_stem=True):\n",
    "        self.positional_index = {}\n",
    "        for doc_id, document in enumerate(self.documents):\n",
    "            terms = self.preprocess_document(document, rm_stop, do_stem)\n",
    "\n",
    "            for position, term in enumerate(terms):\n",
    "                if term not in self.positional_index:\n",
    "                    self.positional_index[term] = {}\n",
    "                if doc_id not in self.positional_index[term]:\n",
    "                    self.positional_index[term][doc_id] = [position]\n",
    "                else:\n",
    "                    self.positional_index[term][doc_id] += [position]\n",
    "\n",
    "    def positional_intersect(self, positions_1, positions_2, kprox):\n",
    "        answer = []\n",
    "\n",
    "        idx_1, idx_2 = 0, 0\n",
    "\n",
    "        while idx_1 < len(positions_1) and idx_2 < len(positions_2):\n",
    "            pos1 = positions_1[idx_1]\n",
    "            while idx_2 < len(positions_2) and pos1 - positions_2[idx_2] > kprox:\n",
    "                idx_2 += 1\n",
    "            j = idx_2\n",
    "            if j < len(positions_2) and abs(positions_2[j] - pos1) <= kprox:\n",
    "                answer += [[pos1, positions_2[j]]]\n",
    "                j += 1\n",
    "            idx_1 += 1\n",
    "        \n",
    "        return answer        \n",
    "\n",
    "    def get_pos_index(self, term):\n",
    "        return self.positional_index.get(term, {})\n",
    "    \n",
    "    def proximity_query(self, query, rm_stop=False, do_stem=True):\n",
    "        terms = re.findall(r'\\b\\w+\\b', query.lower())\n",
    "        if len(terms) != 4 or terms[1] != 'near':\n",
    "            raise UndefinedQueryInputError()\n",
    "        kprox = int(terms[2]) + 1\n",
    "        terms = self.bpreprocess_document(f\"{terms[0]} {terms[3]}\", rm_stop, do_stem)\n",
    "        comm_docs = self.intersect_sorted(list(self.get_pos_index(terms[0]).keys()), list(self.get_pos_index(terms[1]).keys()))\n",
    "        if not comm_docs:\n",
    "            return []\n",
    "        result = []\n",
    "        for doc_id in comm_docs:\n",
    "            ans = self.positional_intersect(self.get_pos_index(terms[0])[doc_id], self.get_pos_index(terms[1])[doc_id], kprox)\n",
    "            if ans:\n",
    "                result += [doc_id]\n",
    "            print(doc_id, ans)\n",
    "        return result\n",
    "\n",
    "    def correct_spelling(self, query):\n",
    "        query_terms = self.bpreprocess_document(query, rm_stop=False, do_stem=False)\n",
    "\n",
    "        corrected_query = []\n",
    "        for term in query_terms:\n",
    "            # Find the closest term in the dataset using Levenshtein distance\n",
    "            closest_term = min(self.all_cterms, key=lambda x: distance(term, x))\n",
    "            corrected_query.append(closest_term)\n",
    "\n",
    "        return ' '.join(corrected_query)\n",
    "\n",
    "    def build_kgram_index(self, k=2):\n",
    "        self.kgram_index = {}\n",
    "        for trm_id, cterm in self.all_kterms.items():\n",
    "            cterm = f\"${cterm}$\"\n",
    "            for i in range(len(cterm) - k + 1):\n",
    "                gram = cterm[i:i+k]\n",
    "                if gram not in self.kgram_index:\n",
    "                    self.kgram_index[gram] = [trm_id]\n",
    "                elif self.kgram_index[gram][-1] != trm_id:\n",
    "                    self.kgram_index[gram] += [trm_id]\n",
    "\n",
    "    def get_kgram_index(self, term):\n",
    "        return self.kgram_index.get(term, [])\n",
    "\n",
    "    def check_kgram(self, query, word):\n",
    "        query = query[1:-1]\n",
    "        for i in range(len(query)):\n",
    "            if '*' == query[i]:\n",
    "                star_pos = i\n",
    "                break\n",
    "            if word[i] != query[i]:\n",
    "                return False\n",
    "        else:\n",
    "            return True\n",
    "        j = len(word) - 1\n",
    "        for i in range(len(query)-1, i, -1):\n",
    "            if '*' == query[i]:\n",
    "                if star_pos < i and query[star_pos+1:i-1] not in word[star_pos+1:j]:\n",
    "                    return False\n",
    "                break\n",
    "            if word[j] != query[i]:\n",
    "                return False\n",
    "            j -= 1\n",
    "        return True\n",
    "    \n",
    "    def wildcard_query_kgram(self, query, do_post=True, k=2):\n",
    "        query = query.lower()\n",
    "        query = f\"${query}$\"\n",
    "        grams = set()\n",
    "        for i in range(len(query) - k + 1):\n",
    "            if '*' not in query[i:i+k]:\n",
    "                grams.add(query[i:i+k])\n",
    "        result = []\n",
    "        for i, gram in enumerate(grams):\n",
    "            if not i:\n",
    "                result = self.get_kgram_index(gram)\n",
    "            else:\n",
    "                result = self.intersect_sorted(result, self.get_kgram_index(gram))\n",
    "            if not result:\n",
    "                return []\n",
    "        result = [self.all_kterms[idx] for idx in result]\n",
    "        if do_post:\n",
    "            result = [word for word in result if self.check_kgram(query, word)]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b750a5ce-6336-40ab-8e6d-d2e82e708d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_system = IRSystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60a64a80-bde0-42e6-907b-1dc4e964f031",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'simple',\n",
       "  'example',\n",
       "  'document',\n",
       "  'it',\n",
       "  'contains',\n",
       "  'several',\n",
       "  'words',\n",
       "  'the',\n",
       "  'words',\n",
       "  'should',\n",
       "  'be',\n",
       "  'processed'],\n",
       " ['another',\n",
       "  'example',\n",
       "  'document',\n",
       "  'with',\n",
       "  'different',\n",
       "  'content',\n",
       "  'spelling',\n",
       "  'correction',\n",
       "  'is',\n",
       "  'important',\n",
       "  'for',\n",
       "  'retrieval'],\n",
       " ['another',\n",
       "  'example',\n",
       "  'document',\n",
       "  'to',\n",
       "  'test',\n",
       "  'boolean',\n",
       "  'search',\n",
       "  'capabilities',\n",
       "  'this',\n",
       "  'document',\n",
       "  'contains',\n",
       "  'relevant',\n",
       "  'content']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.add_document(\"This is a simple example document. It contains several words. The words should be processed.\")\n",
    "ir_system.add_document(\"Another example document with different content. Spelling correction is important for retrieval\")\n",
    "ir_system.add_document(\"Another example document to test Boolean search capabilities. This document contains relevant content.\")\n",
    "ir_system.documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d19844-9b1f-47e2-8657-8a629f343fde",
   "metadata": {},
   "source": [
    "### rm_stop=True, do_stem=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7b410f9-9c69-44e7-bb15-64722aa72610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simpl': [0],\n",
       " 'exampl': [0, 1, 2],\n",
       " 'document': [0, 1, 2],\n",
       " 'contain': [0, 2],\n",
       " 'sever': [0],\n",
       " 'word': [0],\n",
       " 'process': [0],\n",
       " 'anoth': [1, 2],\n",
       " 'differ': [1],\n",
       " 'content': [1, 2],\n",
       " 'spell': [1],\n",
       " 'correct': [1],\n",
       " 'import': [1],\n",
       " 'retriev': [1],\n",
       " 'test': [2],\n",
       " 'boolean': [2],\n",
       " 'search': [2],\n",
       " 'capabl': [2],\n",
       " 'relev': [2]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.build_inverted_index()\n",
    "ir_system.inverted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da965a-93be-4338-846b-5f8457691f30",
   "metadata": {},
   "source": [
    "### Answers are in 0 base mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3db76534-6135-4519-bd05-d3eaa4fe7915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.boolean_query(\"example AND content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec9efc7b-4509-4a11-9558-9ef3847b5232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.boolean_query(\"example or simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e9318-2a65-4be4-ada7-ffdb82a6651d",
   "metadata": {},
   "source": [
    "### It doesn't work because stop words have been removed and \"is\" is no longer in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9752c87c-2e7a-4b0c-8ce2-f3282f15aeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.boolean_query(\"not indexing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "495bf157-d266-4cf0-a343-6de65529842e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.boolean_query(\"not content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331f8f9-811a-49f6-9947-097d8f7126c6",
   "metadata": {},
   "source": [
    "### rm_stop=False, do_stem=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5a83871-c7c4-414f-9ba6-bb08ab7c7429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thi': {0: [0], 2: [8]},\n",
       " 'is': {0: [1], 1: [8]},\n",
       " 'a': {0: [2]},\n",
       " 'simpl': {0: [3]},\n",
       " 'exampl': {0: [4], 1: [1], 2: [1]},\n",
       " 'document': {0: [5], 1: [2], 2: [2, 9]},\n",
       " 'it': {0: [6]},\n",
       " 'contain': {0: [7], 2: [10]},\n",
       " 'sever': {0: [8]},\n",
       " 'word': {0: [9, 11]},\n",
       " 'the': {0: [10]},\n",
       " 'should': {0: [12]},\n",
       " 'be': {0: [13]},\n",
       " 'process': {0: [14]},\n",
       " 'anoth': {1: [0], 2: [0]},\n",
       " 'with': {1: [3]},\n",
       " 'differ': {1: [4]},\n",
       " 'content': {1: [5], 2: [12]},\n",
       " 'spell': {1: [6]},\n",
       " 'correct': {1: [7]},\n",
       " 'import': {1: [9]},\n",
       " 'for': {1: [10]},\n",
       " 'retriev': {1: [11]},\n",
       " 'to': {2: [3]},\n",
       " 'test': {2: [4]},\n",
       " 'boolean': {2: [5]},\n",
       " 'search': {2: [6]},\n",
       " 'capabl': {2: [7]},\n",
       " 'relev': {2: [11]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.build_positional_index()\n",
    "ir_system.positional_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f0e5b5f-8732-4e5e-9b2b-1b5beb92d3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [[1, 5]]\n",
      "2 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.proximity_query(\"example NEAR/3 content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a6505db-3167-4b9e-8179-31400725b2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.proximity_query(\"example NEAR/1 test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3665579-940d-4248-83ce-752e98699b36",
   "metadata": {},
   "source": [
    "### rm_stop=False, do_stem=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "971fb680-736f-4655-b664-09976780fc69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thi': [0, 2],\n",
       " 'is': [0, 1],\n",
       " 'a': [0],\n",
       " 'simpl': [0],\n",
       " 'exampl': [0, 1, 2],\n",
       " 'document': [0, 1, 2],\n",
       " 'it': [0],\n",
       " 'contain': [0, 2],\n",
       " 'sever': [0],\n",
       " 'word': [0],\n",
       " 'the': [0],\n",
       " 'should': [0],\n",
       " 'be': [0],\n",
       " 'process': [0],\n",
       " 'anoth': [1, 2],\n",
       " 'with': [1],\n",
       " 'differ': [1],\n",
       " 'content': [1, 2],\n",
       " 'spell': [1],\n",
       " 'correct': [1],\n",
       " 'import': [1],\n",
       " 'for': [1],\n",
       " 'retriev': [1],\n",
       " 'to': [2],\n",
       " 'test': [2],\n",
       " 'boolean': [2],\n",
       " 'search': [2],\n",
       " 'capabl': [2],\n",
       " 'relev': [2]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.build_inverted_index(rm_stop=False, do_stem=True)\n",
    "ir_system.inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3d0340b-3900-4f0b-b35a-8002de23fb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.boolean_query(\"example AND content\", rm_stop=False, do_stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11f2931a-0908-4cb4-8a78-92e9edade453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.boolean_query(\"example or simple\", rm_stop=False, do_stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a923818-e514-4861-a7db-9701262361e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.boolean_query(\"example or is\", rm_stop=False, do_stem=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d4d492-f00f-48c4-bff5-25e0f4c0c705",
   "metadata": {},
   "source": [
    "### rm_stop=True, do_stem=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a78fa18-32b4-4eae-b43d-a2ade1feb66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simpl': {0: [0]},\n",
       " 'exampl': {0: [1], 1: [1], 2: [1]},\n",
       " 'document': {0: [2], 1: [2], 2: [2, 7]},\n",
       " 'contain': {0: [3], 2: [8]},\n",
       " 'sever': {0: [4]},\n",
       " 'word': {0: [5, 6]},\n",
       " 'process': {0: [7]},\n",
       " 'anoth': {1: [0], 2: [0]},\n",
       " 'differ': {1: [3]},\n",
       " 'content': {1: [4], 2: [10]},\n",
       " 'spell': {1: [5]},\n",
       " 'correct': {1: [6]},\n",
       " 'import': {1: [7]},\n",
       " 'retriev': {1: [8]},\n",
       " 'test': {2: [3]},\n",
       " 'boolean': {2: [4]},\n",
       " 'search': {2: [5]},\n",
       " 'capabl': {2: [6]},\n",
       " 'relev': {2: [9]}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.build_positional_index(rm_stop=True, do_stem=True)\n",
    "ir_system.positional_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17154cbf-5680-4fc6-b71f-5fa15f217d7c",
   "metadata": {},
   "source": [
    "### The output is correct, but in fact, the distance between them is calculated less because the word between them is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "620d9fc9-779e-44a3-a360-85cb3b64944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [[1, 4]]\n",
      "2 []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.proximity_query(\"example NEAR/3 content\", rm_stop=True, do_stem=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6350b-5bdd-4477-bd5e-30af8d9dd353",
   "metadata": {},
   "source": [
    "### The answer is wrong because \"to\", which is a stop word, has been removed, so the distance between these two words has decreased and is acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ece1204d-f72b-457a-b5c7-03703e3832e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [[1, 3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.proximity_query(\"example NEAR/1 test\", rm_stop=True, do_stem=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdac8fc5-0f91-4a3d-b18f-dd6c8d695b08",
   "metadata": {},
   "source": [
    "# correct_spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49ebfce4-9849-45dc-90d4-3438c7014db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ir_system.prep_correct_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f8e1b61-14e1-4e89-a455-79e7dfc35cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'festival founders'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.correct_spelling(\"festivsl funders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7e7f3df-825e-4837-beb6-79988a3ed8fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clone',\n",
       " 'done',\n",
       " 'complaints',\n",
       " '11',\n",
       " 'fixing',\n",
       " 'and',\n",
       " 'worked',\n",
       " 'tires',\n",
       " 'fill',\n",
       " 'whatever',\n",
       " 'inferno',\n",
       " 'cleared',\n",
       " 'upset',\n",
       " 'attendance',\n",
       " 'all',\n",
       " 'shave',\n",
       " 'bob',\n",
       " 'clicked',\n",
       " 'ethnic',\n",
       " 'fines',\n",
       " 'says',\n",
       " 'among',\n",
       " 'gasoline',\n",
       " 'ran',\n",
       " 'antennas',\n",
       " 'aid',\n",
       " 're',\n",
       " 'friendly',\n",
       " 'has',\n",
       " 'acres',\n",
       " 'quieter',\n",
       " 'jail',\n",
       " 'dropped',\n",
       " 'irritating',\n",
       " 'quite',\n",
       " 'bill',\n",
       " 'dominic',\n",
       " 'asked',\n",
       " 'several',\n",
       " 'toaster',\n",
       " 'canine',\n",
       " 'wrong',\n",
       " '50x',\n",
       " 'venice',\n",
       " 'facility',\n",
       " 'reason',\n",
       " 'walks',\n",
       " 'eyesight',\n",
       " 'pianist',\n",
       " '15',\n",
       " 'talk',\n",
       " 'help',\n",
       " 'work',\n",
       " 'vittorios',\n",
       " 'guy',\n",
       " 'vehicles',\n",
       " 'tough',\n",
       " 'batteries',\n",
       " 'alan',\n",
       " 'apply',\n",
       " 'exact',\n",
       " 'provide',\n",
       " 'blocks',\n",
       " 'driver',\n",
       " 'homeowner',\n",
       " 'me',\n",
       " 'man',\n",
       " 'cane',\n",
       " 'convertible',\n",
       " 'surround',\n",
       " 'did',\n",
       " 'week',\n",
       " 'hamburgers',\n",
       " '7',\n",
       " 'heard',\n",
       " 'jumped',\n",
       " 'administration',\n",
       " 'customers',\n",
       " 'seemed',\n",
       " 'respond',\n",
       " 'recent',\n",
       " 'delightful',\n",
       " 'idea',\n",
       " 'johnson',\n",
       " 'feet',\n",
       " 'creek',\n",
       " 'gunshots',\n",
       " 'offset',\n",
       " 'over',\n",
       " 'lived',\n",
       " 'drive',\n",
       " 'lucky',\n",
       " 'so',\n",
       " 'dogs',\n",
       " 'spanish',\n",
       " 'apartments',\n",
       " 'puppies',\n",
       " 'landfill',\n",
       " 'into',\n",
       " 'grabbed',\n",
       " 'i',\n",
       " 'started',\n",
       " 'inevitably',\n",
       " 'bought',\n",
       " 'myself',\n",
       " 'hour',\n",
       " 'nancy',\n",
       " 'angeles',\n",
       " 'make',\n",
       " 'sixth',\n",
       " 'eye',\n",
       " 'behind',\n",
       " 'company',\n",
       " 'private',\n",
       " 'unhappy',\n",
       " 'dolls',\n",
       " 'which',\n",
       " 'uninjured',\n",
       " 'sought',\n",
       " 'sometimes',\n",
       " 'food',\n",
       " 'razors',\n",
       " 'yet',\n",
       " 'arizona',\n",
       " 'candy',\n",
       " 'people',\n",
       " 'state',\n",
       " 'often',\n",
       " 'freeway',\n",
       " 'crazy',\n",
       " 'cycles',\n",
       " 'released',\n",
       " 'california',\n",
       " 'reduce',\n",
       " 'woke',\n",
       " 'higher',\n",
       " 'order',\n",
       " 'before',\n",
       " 'long',\n",
       " 'an',\n",
       " 'lap',\n",
       " 'homebuyers',\n",
       " 'hopes',\n",
       " 'evening',\n",
       " 'burst',\n",
       " 'childless',\n",
       " 'road',\n",
       " 'my',\n",
       " 'phone',\n",
       " 'ice',\n",
       " 'warden',\n",
       " 'neighbors',\n",
       " 'ambulance',\n",
       " '1995',\n",
       " 'where',\n",
       " '75',\n",
       " 'most',\n",
       " '500x',\n",
       " 'am',\n",
       " 'will',\n",
       " 'found',\n",
       " 'bubble',\n",
       " 'sudden',\n",
       " 'prisoners',\n",
       " 'geyser',\n",
       " 'have',\n",
       " 'arrived',\n",
       " 'enough',\n",
       " 'give',\n",
       " 'refill',\n",
       " 'popular',\n",
       " 'books',\n",
       " 'headaches',\n",
       " 'completely',\n",
       " 'next',\n",
       " 'allotments',\n",
       " 'different',\n",
       " 'haven',\n",
       " 'nitrogen',\n",
       " 'managed',\n",
       " 'way',\n",
       " 'newsstand',\n",
       " 'bicycles',\n",
       " 'last',\n",
       " 'festival',\n",
       " 'annual',\n",
       " 'through',\n",
       " 'party',\n",
       " 'kitten',\n",
       " 'life',\n",
       " 'gangsters',\n",
       " 'other',\n",
       " 'tree',\n",
       " 'unpredictable',\n",
       " 'wheel',\n",
       " '25',\n",
       " 'coffee',\n",
       " 'implanted',\n",
       " 'items',\n",
       " 'hot',\n",
       " 'property',\n",
       " 'lot',\n",
       " 'sparing',\n",
       " 'greater',\n",
       " 'movie',\n",
       " 'grand',\n",
       " 'able',\n",
       " 'joy',\n",
       " 'also',\n",
       " 'perfect',\n",
       " 'avoided',\n",
       " 'taxes',\n",
       " 'minor',\n",
       " 'legal',\n",
       " 'percent',\n",
       " 'lives',\n",
       " 'condo',\n",
       " 'head',\n",
       " 'magazines',\n",
       " 'nice',\n",
       " 'band',\n",
       " 'apartment',\n",
       " 'visitors',\n",
       " 'sports',\n",
       " 'succeed',\n",
       " 'area',\n",
       " 'donna',\n",
       " 'embrace',\n",
       " 'luxury',\n",
       " 'clones',\n",
       " 'lawn',\n",
       " 'thick',\n",
       " 'telling',\n",
       " 'ration',\n",
       " 'social',\n",
       " 'attract',\n",
       " 'rick',\n",
       " 'dozen',\n",
       " 'hawaiian',\n",
       " 'event',\n",
       " 'english',\n",
       " 'economy',\n",
       " 'course',\n",
       " 'erupted',\n",
       " 'baby',\n",
       " 'employee',\n",
       " 'woman',\n",
       " 'vittorio',\n",
       " 'take',\n",
       " 'forward',\n",
       " 'burger',\n",
       " 'doors',\n",
       " 'job',\n",
       " 'played',\n",
       " 'personal',\n",
       " '12',\n",
       " 'veterinarian',\n",
       " 'off',\n",
       " 'tell',\n",
       " 'plates',\n",
       " 'plot',\n",
       " 'sue',\n",
       " 'barget',\n",
       " 'young',\n",
       " 'refused',\n",
       " 'sunday',\n",
       " 'married',\n",
       " 'chef',\n",
       " 'birder',\n",
       " 'for',\n",
       " 'teen',\n",
       " 'set',\n",
       " 'under',\n",
       " 'post',\n",
       " 'raging',\n",
       " 'lowest',\n",
       " 'whiskey',\n",
       " 'kick',\n",
       " 'apparent',\n",
       " 'tax',\n",
       " 'ought',\n",
       " 'correct',\n",
       " 'ok',\n",
       " 'away',\n",
       " 'finally',\n",
       " 'deal',\n",
       " 'outdoors',\n",
       " 'club',\n",
       " 'rent',\n",
       " '50',\n",
       " 'carts',\n",
       " 'rainstorm',\n",
       " 'its',\n",
       " 'breakfast',\n",
       " 'boy',\n",
       " '90',\n",
       " 'amounts',\n",
       " 'sandwiches',\n",
       " 'much',\n",
       " 'steep',\n",
       " 'elevation',\n",
       " 'april',\n",
       " 'changing',\n",
       " 'issued',\n",
       " 'safely',\n",
       " 'nine',\n",
       " 'heads',\n",
       " 'sam',\n",
       " 'street',\n",
       " 'slam',\n",
       " 'environmental',\n",
       " 'stray',\n",
       " 'nicest',\n",
       " 'such',\n",
       " 'm',\n",
       " 'tv',\n",
       " 'came',\n",
       " 'budget',\n",
       " 'cheap',\n",
       " 'reading',\n",
       " 'less',\n",
       " 'sometime',\n",
       " 'departments',\n",
       " '87',\n",
       " 'repairs',\n",
       " 'rates',\n",
       " 'deals',\n",
       " 'miles',\n",
       " 'town',\n",
       " 'amputated',\n",
       " 'condominium',\n",
       " 'liquid',\n",
       " 'say',\n",
       " 'hospital',\n",
       " 'use',\n",
       " 'little',\n",
       " 'huge',\n",
       " 'website',\n",
       " 'should',\n",
       " 'vendor',\n",
       " 'value',\n",
       " 'allen',\n",
       " 'getting',\n",
       " 'cream',\n",
       " 'called',\n",
       " 'southern',\n",
       " '1000x',\n",
       " 'does',\n",
       " 'following',\n",
       " 'looking',\n",
       " 'canton',\n",
       " 'handle',\n",
       " 'variable',\n",
       " 'stationery',\n",
       " 'saw',\n",
       " '99',\n",
       " 'empty',\n",
       " 'phoenix',\n",
       " 'as',\n",
       " 'toppled',\n",
       " 'pay',\n",
       " 'fresh',\n",
       " 'grocery',\n",
       " 'their',\n",
       " 'suffered',\n",
       " 'soap',\n",
       " 'theater',\n",
       " 'ready',\n",
       " 'gloves',\n",
       " 'worth',\n",
       " 'range',\n",
       " '100x',\n",
       " 'plowed',\n",
       " 'blue',\n",
       " 'slowly',\n",
       " 'stop',\n",
       " 'price',\n",
       " 'counts',\n",
       " '1',\n",
       " 'line',\n",
       " 'bulbs',\n",
       " 'sizes',\n",
       " 'disease',\n",
       " 'anything',\n",
       " 'security',\n",
       " 'shorter',\n",
       " 'wait',\n",
       " 'tower',\n",
       " 'trying',\n",
       " 'sad',\n",
       " 'nonfat',\n",
       " 'more',\n",
       " 'retired',\n",
       " 'female',\n",
       " 'steadily',\n",
       " 'free',\n",
       " 'return',\n",
       " 'born',\n",
       " 'watch',\n",
       " 'contestant',\n",
       " 'playing',\n",
       " 'would',\n",
       " 'messages',\n",
       " 'stolen',\n",
       " 'plus',\n",
       " 'walked',\n",
       " 'avenue',\n",
       " 'owns',\n",
       " 'directions',\n",
       " 'invite',\n",
       " 'out',\n",
       " 'yourself',\n",
       " 'sicker',\n",
       " 'though',\n",
       " 'damage',\n",
       " 'beach',\n",
       " 'we',\n",
       " 'paid',\n",
       " 'cells',\n",
       " 'that',\n",
       " 'along',\n",
       " 'waiting',\n",
       " 'spewed',\n",
       " 'standing',\n",
       " 'plastic',\n",
       " 'influence',\n",
       " 'bus',\n",
       " 'happened',\n",
       " 'bags',\n",
       " 'least',\n",
       " 'hourly',\n",
       " 'drivers',\n",
       " 'oil',\n",
       " 'injured',\n",
       " 'million',\n",
       " 'consisting',\n",
       " 'regular',\n",
       " 'halloween',\n",
       " 'howard',\n",
       " 'themselves',\n",
       " 'thing',\n",
       " 'yield',\n",
       " 'balls',\n",
       " 'seekers',\n",
       " 'rest',\n",
       " 'remaining',\n",
       " 'goes',\n",
       " 'abuse',\n",
       " 'water',\n",
       " 'director',\n",
       " 'plants',\n",
       " 'considerate',\n",
       " 'pile',\n",
       " 'why',\n",
       " 'stand',\n",
       " 'dies',\n",
       " 'drinks',\n",
       " 'weeks',\n",
       " 'around',\n",
       " 'moved',\n",
       " 'gets',\n",
       " 'decide',\n",
       " 'ruined',\n",
       " 'renters',\n",
       " 'negotiations',\n",
       " 'these',\n",
       " 'pistol',\n",
       " 'selected',\n",
       " '280',\n",
       " 'ever',\n",
       " 'golf',\n",
       " 'santa',\n",
       " 'changed',\n",
       " 'player',\n",
       " 'except',\n",
       " 'won',\n",
       " 'gift',\n",
       " 'scheduled',\n",
       " 'shiny',\n",
       " 'tired',\n",
       " 'yelling',\n",
       " 'sued',\n",
       " 'together',\n",
       " 'year',\n",
       " 'kids',\n",
       " 'delivers',\n",
       " 'left',\n",
       " 'carson',\n",
       " 'knew',\n",
       " 'blanket',\n",
       " 'hours',\n",
       " 'officer',\n",
       " 'saxophone',\n",
       " 'alone',\n",
       " 'meeting',\n",
       " 'generating',\n",
       " 'downtown',\n",
       " 'him',\n",
       " 'proven',\n",
       " 'game',\n",
       " 'one',\n",
       " 'eight',\n",
       " 'prince',\n",
       " 'wheels',\n",
       " 'libraries',\n",
       " 'channels',\n",
       " 'estimated',\n",
       " 'complied',\n",
       " 'lake',\n",
       " 'gas',\n",
       " 'almost',\n",
       " '3',\n",
       " 'police',\n",
       " 'appears',\n",
       " 'complications',\n",
       " 'cheaper',\n",
       " 'manager',\n",
       " 'but',\n",
       " 'owner',\n",
       " 'limp',\n",
       " 'toilet',\n",
       " 'bartering',\n",
       " 'put',\n",
       " 'saxophonist',\n",
       " 'anyone',\n",
       " 'community',\n",
       " 'come',\n",
       " 'thousands',\n",
       " 'clockwork',\n",
       " 'home',\n",
       " '9',\n",
       " 'clearing',\n",
       " 'winnings',\n",
       " 'sandwich',\n",
       " 'barco',\n",
       " 'tank',\n",
       " 'teenager',\n",
       " 'd',\n",
       " 'los',\n",
       " 'homeowners',\n",
       " 'nevertheless',\n",
       " 'widowed',\n",
       " 'kittens',\n",
       " 'best',\n",
       " 'minutes',\n",
       " 'what',\n",
       " 'of',\n",
       " 'brand',\n",
       " 'even',\n",
       " 'survive',\n",
       " 'donate',\n",
       " 'first',\n",
       " 'rather',\n",
       " 'black',\n",
       " 'handed',\n",
       " 'between',\n",
       " 'boots',\n",
       " 'color',\n",
       " '3037',\n",
       " 'fruit',\n",
       " 'pretty',\n",
       " 'ended',\n",
       " 'ammunition',\n",
       " 'nationwide',\n",
       " 'thelma',\n",
       " 'find',\n",
       " 'currently',\n",
       " 'clothing',\n",
       " 'insurance',\n",
       " 'own',\n",
       " 'talks',\n",
       " 'demanding',\n",
       " 'sure',\n",
       " 'from',\n",
       " 'chase',\n",
       " 'right',\n",
       " 'bad',\n",
       " 'realtor',\n",
       " 'smiled',\n",
       " 'threw',\n",
       " 'love',\n",
       " 'clients',\n",
       " 'newspaper',\n",
       " 'once',\n",
       " 'shopping',\n",
       " 'couldn',\n",
       " 'revolver',\n",
       " 'proceeds',\n",
       " 'response',\n",
       " 'milkplus',\n",
       " 'inconsiderate',\n",
       " '5',\n",
       " 't',\n",
       " 'sent',\n",
       " 'very',\n",
       " 'made',\n",
       " 'early',\n",
       " 'restaurant',\n",
       " 'children',\n",
       " 'actually',\n",
       " 'hotel',\n",
       " 'goal',\n",
       " 'offer',\n",
       " 'drove',\n",
       " 'streambed',\n",
       " 'every',\n",
       " 'late',\n",
       " 'guarantee',\n",
       " '120',\n",
       " 'brakes',\n",
       " 'practiced',\n",
       " 'loved',\n",
       " 'crew',\n",
       " 'braked',\n",
       " 'could',\n",
       " 'station',\n",
       " 'this',\n",
       " 'sleeping',\n",
       " 'about',\n",
       " 'allowing',\n",
       " 'baldwin',\n",
       " 'hope',\n",
       " 'up',\n",
       " 'dom',\n",
       " 'portable',\n",
       " 'us',\n",
       " 'cloning',\n",
       " 'they',\n",
       " 'seashell',\n",
       " 'problem',\n",
       " 'music',\n",
       " 'loud',\n",
       " 'notify',\n",
       " 've',\n",
       " 'stretch',\n",
       " 'cars',\n",
       " 'summer',\n",
       " 'he',\n",
       " 'book',\n",
       " 'six',\n",
       " 'unemployed',\n",
       " 'authors',\n",
       " 'homes',\n",
       " 'streets',\n",
       " 'hit',\n",
       " 'department',\n",
       " 'necessary',\n",
       " 'carriages',\n",
       " 'fact',\n",
       " 'kinds',\n",
       " 'rattle',\n",
       " 'families',\n",
       " 'carpenter',\n",
       " 'went',\n",
       " 'how',\n",
       " 'minimum',\n",
       " 'growing',\n",
       " 'foot',\n",
       " 'reduced',\n",
       " 'hurriedly',\n",
       " 'underbrush',\n",
       " 'visiting',\n",
       " 'unlucky',\n",
       " 'overpaying',\n",
       " 'fine',\n",
       " 'berserk',\n",
       " 'leftovers',\n",
       " 'silverware',\n",
       " 'cause',\n",
       " 'careful',\n",
       " 'until',\n",
       " 'if',\n",
       " 'allow',\n",
       " 'saved',\n",
       " 'only',\n",
       " 'months',\n",
       " 'sold',\n",
       " 'letting',\n",
       " 'nearby',\n",
       " 'rents',\n",
       " 'bookstore',\n",
       " 'nonflammable',\n",
       " 'seem',\n",
       " 'local',\n",
       " 'whales',\n",
       " 'foothill',\n",
       " 'sponsored',\n",
       " 'autograph',\n",
       " 'two',\n",
       " 'pros',\n",
       " 'federal',\n",
       " 'cup',\n",
       " 'month',\n",
       " 'yellow',\n",
       " 'burn',\n",
       " 'look',\n",
       " 'while',\n",
       " 'collection',\n",
       " 'excitedly',\n",
       " 'sneaking',\n",
       " 'cost',\n",
       " 'studio',\n",
       " 'incomes',\n",
       " 'part',\n",
       " 'suggested',\n",
       " 'not',\n",
       " 'birding',\n",
       " 'bigger',\n",
       " 'shaking',\n",
       " 'never',\n",
       " 'bowling',\n",
       " 'hamilton',\n",
       " 'took',\n",
       " 'bizarre',\n",
       " 'market',\n",
       " 'elsewhere',\n",
       " 'fantastic',\n",
       " 'happy',\n",
       " 'spring',\n",
       " 'monica',\n",
       " 'inmates',\n",
       " 'mountain',\n",
       " 'volunteers',\n",
       " 'trucks',\n",
       " 'decision',\n",
       " 'outside',\n",
       " 'caliber',\n",
       " 'play',\n",
       " 'down',\n",
       " 'husband',\n",
       " 'parked',\n",
       " 'during',\n",
       " 'ago',\n",
       " 'average',\n",
       " 'told',\n",
       " 'horsetrail',\n",
       " 'just',\n",
       " 'officers',\n",
       " 'store',\n",
       " 'death',\n",
       " 'cat',\n",
       " 'go',\n",
       " 'immediately',\n",
       " 'bottle',\n",
       " 'given',\n",
       " 'landlord',\n",
       " 'afghan',\n",
       " '300',\n",
       " 'blind',\n",
       " 'suv',\n",
       " 'gun',\n",
       " 'coin',\n",
       " 'herman',\n",
       " 'movies',\n",
       " 'comic',\n",
       " 'passing',\n",
       " 'them',\n",
       " 'try',\n",
       " 'paying',\n",
       " 'city',\n",
       " 'do',\n",
       " 'neighbor',\n",
       " '76',\n",
       " 'still',\n",
       " 'saying',\n",
       " 'details',\n",
       " 'turned',\n",
       " 'nutritious',\n",
       " 'want',\n",
       " 'place',\n",
       " 'however',\n",
       " 'cities',\n",
       " 'bay',\n",
       " 'totally',\n",
       " 'charged',\n",
       " 'died',\n",
       " 'lozano',\n",
       " 'according',\n",
       " 'tuner',\n",
       " 'run',\n",
       " 'amount',\n",
       " 'something',\n",
       " 'here',\n",
       " 'causing',\n",
       " 'seller',\n",
       " 'pursuing',\n",
       " 'driving',\n",
       " 'in',\n",
       " 'cultured',\n",
       " 'pulp',\n",
       " '150',\n",
       " 'there',\n",
       " 'noise',\n",
       " 'friends',\n",
       " 'audience',\n",
       " 'cube',\n",
       " 'per',\n",
       " 'liked',\n",
       " 'produce',\n",
       " 'crews',\n",
       " 'created',\n",
       " 'whole',\n",
       " 'latest',\n",
       " 'who',\n",
       " 'feel',\n",
       " 'west',\n",
       " 'practice',\n",
       " 'car',\n",
       " 'backbreaking',\n",
       " 'it',\n",
       " 'bang',\n",
       " 'side',\n",
       " 'cigarettes',\n",
       " 'doesn',\n",
       " 'money',\n",
       " 'by',\n",
       " 'new',\n",
       " 'oceanside',\n",
       " 'john',\n",
       " '200',\n",
       " 'assisted',\n",
       " 'francisco',\n",
       " 'couple',\n",
       " '1x',\n",
       " 'spill',\n",
       " 'restored',\n",
       " 'pasadena',\n",
       " 'american',\n",
       " 'slightly',\n",
       " 'debris',\n",
       " 'cutting',\n",
       " 'wasn',\n",
       " 'government',\n",
       " 'radios',\n",
       " 'well',\n",
       " 'collision',\n",
       " 'were',\n",
       " 'material',\n",
       " 'weaned',\n",
       " 'times',\n",
       " 'scouts',\n",
       " 'resident',\n",
       " 'everyone',\n",
       " 'colors',\n",
       " 'happen',\n",
       " 'might',\n",
       " 'anniversary',\n",
       " 'savings',\n",
       " 'supposed',\n",
       " 'let',\n",
       " 'proprietor',\n",
       " 'altadena',\n",
       " 'better',\n",
       " 'income',\n",
       " 'didn',\n",
       " 'five',\n",
       " 'southland',\n",
       " 'sherman',\n",
       " 'great',\n",
       " 'taken',\n",
       " 'millions',\n",
       " 'discovered',\n",
       " 'boxes',\n",
       " 'remarked',\n",
       " 'mrs',\n",
       " 'talked',\n",
       " 'had',\n",
       " 'removed',\n",
       " 'hadn',\n",
       " 'be',\n",
       " 'either',\n",
       " 'win',\n",
       " 'know',\n",
       " 'bummer',\n",
       " 'sign',\n",
       " 'same',\n",
       " 'room',\n",
       " 'second',\n",
       " 'major',\n",
       " 'drought',\n",
       " 'guess',\n",
       " 'everett',\n",
       " 'correctly',\n",
       " 'barney',\n",
       " 'bullet',\n",
       " 'flipped',\n",
       " 'auto',\n",
       " 'church',\n",
       " 'question',\n",
       " 'back',\n",
       " 'outdoor',\n",
       " 'quell',\n",
       " 'gear',\n",
       " 'cans',\n",
       " 'full',\n",
       " 'asking',\n",
       " 'lined',\n",
       " 'jerry',\n",
       " 'than',\n",
       " 'brush',\n",
       " 'dirt',\n",
       " 'is',\n",
       " '10',\n",
       " 'paper',\n",
       " 'house',\n",
       " 'teenage',\n",
       " 'approved',\n",
       " 'sale',\n",
       " 'prices',\n",
       " 'mind',\n",
       " 'reduction',\n",
       " 'correctional',\n",
       " 'cone',\n",
       " 'decided',\n",
       " 'sickness',\n",
       " 'picked',\n",
       " 'county',\n",
       " '1993',\n",
       " 'secured',\n",
       " 'lottery',\n",
       " 'cell',\n",
       " 'specter',\n",
       " '20',\n",
       " 'rental',\n",
       " 'white',\n",
       " 'spinning',\n",
       " 'numbers',\n",
       " 'roof',\n",
       " 'earring',\n",
       " 'surcharge',\n",
       " 'skyrocketing',\n",
       " 'ordering',\n",
       " 'don',\n",
       " 'item',\n",
       " 'stain',\n",
       " 'time',\n",
       " 'since',\n",
       " 'making',\n",
       " 'newest',\n",
       " 'failure',\n",
       " 'gave',\n",
       " '50th',\n",
       " 'big',\n",
       " 'watches',\n",
       " 'emphysema',\n",
       " 'already',\n",
       " 'sell',\n",
       " 'think',\n",
       " 'octane',\n",
       " 'future',\n",
       " 'nobody',\n",
       " 'dining',\n",
       " 'wife',\n",
       " 'loan',\n",
       " 'saturday',\n",
       " 'diabetes',\n",
       " 'bikers',\n",
       " 'twice',\n",
       " 'fee',\n",
       " 'scared',\n",
       " '1000',\n",
       " 'mild',\n",
       " 'samantha',\n",
       " 'listen',\n",
       " 'permitted',\n",
       " 'reconsider',\n",
       " 'said',\n",
       " 'wearing',\n",
       " 'gangster',\n",
       " 'widow',\n",
       " 'three',\n",
       " 'births',\n",
       " 'lee',\n",
       " 'offers',\n",
       " 'burned',\n",
       " 'boon',\n",
       " 'extra',\n",
       " 'must',\n",
       " 'dreamily',\n",
       " 'save',\n",
       " 'guessed',\n",
       " 'estrus',\n",
       " 'both',\n",
       " 'raining',\n",
       " 'night',\n",
       " 'loans',\n",
       " 'washes',\n",
       " 'lose',\n",
       " 'bring',\n",
       " 'toyola',\n",
       " 'attitudes',\n",
       " 'officials',\n",
       " 'front',\n",
       " 's',\n",
       " 'guards',\n",
       " 'penny',\n",
       " 'close',\n",
       " 'you',\n",
       " 'slacks',\n",
       " 'complain',\n",
       " ...}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.all_cterms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fd358d9-b0f0-4be3-9965-87725a3838e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'nobody' in ir_system.all_cterms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a0d16fb-3d48-4a3c-84b1-16b5d69d6678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ir_system.build_kgram_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "135a5a0b-0178-4d4c-ba10-8fa397f2081d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 167,\n",
       " 212,\n",
       " 241,\n",
       " 390,\n",
       " 632,\n",
       " 681,\n",
       " 705,\n",
       " 776,\n",
       " 792,\n",
       " 872,\n",
       " 950,\n",
       " 1002,\n",
       " 1017,\n",
       " 1021,\n",
       " 1058,\n",
       " 1101,\n",
       " 1163,\n",
       " 1174]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.get_kgram_index(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bac55877-85af-4db7-a6f1-6c310009157c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nobody']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.wildcard_query_kgram(\"nobo*y\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3652f053-90f9-41b9-9a4a-488a107ff669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nobody']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.wildcard_query_kgram(\"nobody\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aeaec7-9a6c-41c1-ae73-7345ee0912c5",
   "metadata": {},
   "source": [
    "### We have to do post filter. (nobobody != nobody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a622839-48a7-45ca-8a93-c5347f0a706c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nobody']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.wildcard_query_kgram(\"nobobody\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a480ce00-12fb-4f72-bfec-c80c532a3ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.check_kgram(\"$nobo*y$\", \"nobody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d73a8b38-a7b1-418b-9ed1-bad25d611a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.wildcard_query_kgram(\"nobobody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88dcf766-4d5f-4bf1-8c0d-dfe2eea45be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nobody']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.wildcard_query_kgram(\"nobo*y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588bf181-21a7-4070-bacc-21980d0aa819",
   "metadata": {},
   "source": [
    "## K=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d99ea85c-308f-4921-8c4c-3a087a6067d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_system.build_kgram_index(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42a43cfb-ba1a-48d1-aa76-8994213e4b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[390, 632, 681, 705, 792, 950, 1002, 1021, 1163, 1174]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.get_kgram_index(\"$no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3607ee8d-dac0-4608-a388-c925470ace33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nobody']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.wildcard_query_kgram(\"nobody\", False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f263e69-9e46-4be4-b8b7-f5e93c276a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.wildcard_query_kgram(\"nobobody\", False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83de7348-2a9f-4177-98db-020bde8a230c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nobody']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir_system.wildcard_query_kgram(\"nobody\", k=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
